{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "deletable": false,
    "editable": false,
    "id": "ZK0QB-Qe29ug",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d273675751b20a3e1e69a353fc227cfc",
     "grade": false,
     "grade_id": "cell-c9d79ad28495f780",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "# Transfer Learning\n",
    "\n",
    "We've already looked an example of transfer learning when working with application in Natural Language Processing. For sentiment classification, we used various feature representations including using GloVe representations as the chosen word embedding. That was one example of transfer learning where the approach we used was a feature representation transfer.\n",
    "\n",
    "In this exercise we will apply transfer learning to computer vision where we will incorporate both parameter transfer as well as feature representation transfer. You can take a look at the available pre-trained models in keras on the [applications page](https://keras.io/applications) in the documentation. In practice, we rarely build a model from scratch and instead use transfer learning to gain the benefit of state of the art models.\n",
    "\n",
    "For thie exercise, we will use the [CIFAR10 dataset](https://keras.io/datasets/#cifar10-small-image-classification)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 615
    },
    "colab_type": "code",
    "id": "fovKzoey3ZV2",
    "outputId": "2eeb4037-8488-469b-a0fa-44666d203dec"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow==2.0 in /usr/local/lib/python3.6/dist-packages (2.0.0)\n",
      "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0) (1.11.2)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0) (1.1.0)\n",
      "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0) (0.8.1)\n",
      "Requirement already satisfied: tensorboard<2.1.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0) (2.0.1)\n",
      "Requirement already satisfied: gast==0.2.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0) (0.2.2)\n",
      "Requirement already satisfied: tensorflow-estimator<2.1.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0) (2.0.1)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0) (1.1.0)\n",
      "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0) (0.33.6)\n",
      "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0) (0.8.0)\n",
      "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0) (1.0.8)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0) (1.15.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0) (0.1.8)\n",
      "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0) (3.10.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0) (3.1.0)\n",
      "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0) (1.12.0)\n",
      "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0) (1.17.4)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow==2.0) (1.7.1)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow==2.0) (41.4.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow==2.0) (3.1.1)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow==2.0) (0.16.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow==2.0) (0.4.1)\n",
      "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow==2.0) (2.8.0)\n",
      "Requirement already satisfied: rsa<4.1,>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0) (4.0)\n",
      "Requirement already satisfied: cachetools<3.2,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0) (3.1.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0) (0.2.7)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0) (1.3.0)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa<4.1,>=3.1.4->google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0) (0.4.7)\n",
      "Requirement already satisfied: requests>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0) (2.21.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0) (3.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0) (2019.9.11)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0) (3.0.4)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0) (2.8)\n",
      "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0) (1.24.3)\n"
     ]
    }
   ],
   "source": [
    "! pip install tensorflow==2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "deletable": false,
    "editable": false,
    "id": "eKv9jr6y29uh",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c6baa89a1f6e8a324a2c0f73b424c3fd",
     "grade": false,
     "grade_id": "cell-efba043cb3f09871",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "from tensorflow.keras import Model\n",
    "\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "num_classes=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 221
    },
    "colab_type": "code",
    "id": "W5c4ABup29uk",
    "outputId": "20029794-c6d2-4aaf-b241-e10cd0f2d869"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[name: \"/device:CPU:0\"\n",
       " device_type: \"CPU\"\n",
       " memory_limit: 268435456\n",
       " locality {\n",
       " }\n",
       " incarnation: 3755763710098626315, name: \"/device:XLA_CPU:0\"\n",
       " device_type: \"XLA_CPU\"\n",
       " memory_limit: 17179869184\n",
       " locality {\n",
       " }\n",
       " incarnation: 11062436089583643920\n",
       " physical_device_desc: \"device: XLA_CPU device\"]"
      ]
     },
     "execution_count": 3,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "device_lib.list_local_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "deletable": false,
    "editable": false,
    "id": "4GYIl8Z929um",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0a085a3e907fd22237f828179d8e90eb",
     "grade": false,
     "grade_id": "cell-da2aa308afa6cd45",
     "locked": true,
     "schema_version": 3,
     "solution": false
    },
    "outputId": "905406a6-edef-481c-ec65-e72b9a8b46c9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((50000, 32, 32, 3), (50000, 1))"
      ]
     },
     "execution_count": 4,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "tX9hmk2u29up",
    "outputId": "93aa18bf-e6f2-4519-c42c-bfa06dc694b4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 9)"
      ]
     },
     "execution_count": 5,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.min(), y_train.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "deletable": false,
    "editable": false,
    "id": "9monHu4w29ur",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "00cf449dc4d14f90fff998cd9a087ef3",
     "grade": false,
     "grade_id": "cell-00565449f93db419",
     "locked": true,
     "schema_version": 3,
     "solution": false
    },
    "outputId": "af079061-257c-45c0-b33b-21d395376c65"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10000, 32, 32, 3), (10000, 1))"
      ]
     },
     "execution_count": 6,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "v3TRNFpe29uu",
    "outputId": "2b98384b-f68c-461c-bee6-85faf9eac853"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((50000, 10), (10000, 10), 0.0, 1.0)"
      ]
     },
     "execution_count": 7,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "y_train.shape, y_test.shape, y_train.min(), y_train.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "deletable": false,
    "editable": false,
    "id": "VLojbF_y29uw",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "6142f6b53a1c2fef034113ebd40cfdd2",
     "grade": false,
     "grade_id": "cell-46a3e8197a25e135",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "First, we will use a VGG-16 model to extract features from a sample. The VGG-16 model without the fully connected layers is equivalent to just the pretrained convolutional layers. By passing data through the model we are able to extract features based on the knowledge from the pretrained imagenet dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "deletable": false,
    "id": "O0UbGWXG29uw",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4d0f572ffafa7ad9be978fb6832282f6",
     "grade": false,
     "grade_id": "cell-cbf2a8f1fde34aa8",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# Load a VGG16 model with imagenet weights, without the fully connected layers, and with the adjusted input shape for our data\n",
    "# Save the model as vgg_model\n",
    "\n",
    "# YOUR CODE HERE\n",
    "vgg_model = VGG16(weights='imagenet', include_top=False, input_shape=(32,32,3))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "deletable": false,
    "editable": false,
    "id": "Dbu8oIlR29uz",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c0ef0c7b96d2bce168920de695e896d4",
     "grade": true,
     "grade_id": "cell-7cc41b089035d39a",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert vgg_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "k5bcusQE29u1",
    "outputId": "693046a6-69b9-4c05-896b-0636c67e100c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 32, 3)"
      ]
     },
     "execution_count": 10,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example = x_train[10]\n",
    "example.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 266
    },
    "colab_type": "code",
    "id": "vr3zWYFy29u3",
    "outputId": "18077ce6-0e29-40cb-e2a2-67811a3e9919"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD5CAYAAADhukOtAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(example)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "deletable": false,
    "id": "o20nU55q29u5",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "738a81836e1e43319cea901589117ca8",
     "grade": false,
     "grade_id": "cell-9efc493f08237ae8",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# Use the vgg_model you loaded to extract the features for the example image\n",
    "# save the output to example_vgg\n",
    "\n",
    "# YOUR CODE HERE\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "example_vgg = vgg_model.predict(example.reshape(1,32,32,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "deletable": false,
    "editable": false,
    "id": "Zby2WmLm29u7",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5a354bd81201b8539fa818c87b10bd40",
     "grade": true,
     "grade_id": "cell-0c7351fe695136f1",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert np.squeeze(example_vgg).shape == (512,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "deletable": false,
    "editable": false,
    "id": "jScYKddy29u9",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "8d73ebb92599fa82a0100ee73fdd2880",
     "grade": false,
     "grade_id": "cell-8d58e4bfcd6581ec",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "Now let's create our own fully connected layers and add those after the `vgg_model`. We can then predict train our model on the CIFAR10 dataset and predict its classes. In the following code, you'll want to use Keras' [functional API](https://www.tensorflow.org/guide/keras/functional) that we've used before. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "deletable": false,
    "id": "l1NSc1W929u9",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8ee531a956af34e77fbcec998bac3138",
     "grade": false,
     "grade_id": "cell-2dbbcd51c1a9bcf5",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# Flatten the Convolutional layers' output then\n",
    "# Add 3 Dense layers with 256 units each followed by the output layer\n",
    "# Use the functional API to do this\n",
    "# Save the final output from the layers as `predictions`\n",
    "\n",
    "x = vgg_model.output\n",
    "# YOUR CODE HERE\n",
    "\n",
    "\n",
    "x = Flatten()(x)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "predictions = Dense(10, activation='softmax')(x)\n",
    "\n",
    "vgg_complete = Model(vgg_model.input, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "deletable": false,
    "editable": false,
    "id": "9pzP0sXj29u_",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "97cf91aa294f3ffbbab690eebec68821",
     "grade": true,
     "grade_id": "cell-ccdc0af6567cf083",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert len(vgg_complete.layers) - len(vgg_model.layers) == 5\n",
    "assert vgg_complete.layers[-2].units == 256\n",
    "assert vgg_complete.layers[-3].units == 256\n",
    "assert vgg_complete.layers[-4].units == 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 969
    },
    "colab_type": "code",
    "id": "5u6ZsEW-29vB",
    "outputId": "bfb91097-aee0-45e8-c286-b7132954355b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 32, 32, 3)]       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 32, 32, 64)        1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 32, 32, 64)        36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 16, 16, 128)       73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 16, 16, 128)       147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 8, 8, 256)         295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 8, 8, 256)         590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 8, 8, 256)         590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 4, 4, 512)         1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 4, 4, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 4, 4, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 2, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 2, 2, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 2, 2, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 2, 2, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 1, 1, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 14,980,170\n",
      "Trainable params: 14,980,170\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vgg_complete.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Af5fGjbY29vD"
   },
   "outputs": [],
   "source": [
    "# Keep the feature extraction weights as is from the trained ImageNet\n",
    "# This will reduce the time it takes to train the model\n",
    "# Try setting the value to True instead and run the next cell to look at the difference in ETA.\n",
    "for layer in vgg_model.layers:\n",
    "    layer.trainable=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "deletable": false,
    "editable": false,
    "id": "okTU4d1j29vF",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ec81d20401a4869948014ee7d7e78a64",
     "grade": false,
     "grade_id": "cell-555ef11edc47dba7",
     "locked": true,
     "schema_version": 3,
     "solution": false
    },
    "outputId": "90be58e1-7af0-47ba-de9d-0176d0ba5df2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples\n",
      "45952/50000 [==========================>...] - ETA: 49s - loss: 1.6531 - accuracy: 0.4888"
     ]
    }
   ],
   "source": [
    "# This cell will take a while. Double check your work before continuing\n",
    "vgg_complete.compile(\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "vgg_complete.fit(x_train, y_train, epochs=1, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "deletable": false,
    "id": "hQsFJoHU29vG",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8d0e7056fc8a9484386dd38f07728bdc",
     "grade": false,
     "grade_id": "cell-ce8717f26f9f5d79",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# Report the accuracy on the test set\n",
    "# Save it as acc\n",
    "\n",
    "# YOUR CODE HERE\n",
    "[loss , acc]=vgg_complete.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "deletable": false,
    "editable": false,
    "id": "dqDBzldD29vI",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "18b16fcf9ae16b9cd14912d902f038db",
     "grade": true,
     "grade_id": "cell-eb960da5a7f7d0ab",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert acc > 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "deletable": false,
    "editable": false,
    "id": "zMmF1lXv29vM",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e86f2671f8c1880306cd30d2a338be4d",
     "grade": false,
     "grade_id": "cell-7de667b2ebfee86b",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "print(f\"If you were to guess just one class all the time, your accuracy would be 0.1. Your model accuracy is {acc:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "deletable": false,
    "editable": false,
    "id": "43d3CbGu29vP",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "feac2b34a20fc9f52ac6606cac738ac9",
     "grade": false,
     "grade_id": "cell-d77ae0b5a37d13a7",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "## Feedback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "deletable": false,
    "id": "Qh1AK9G129vQ",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ed936ab53a1391c5e6af8df699a1dbf5",
     "grade": false,
     "grade_id": "feedback",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def feedback():\n",
    "    \"\"\"Provide feedback on the contents of this exercise\n",
    "    \n",
    "    Returns:\n",
    "        string\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    return \"This will help with \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "deletable": false,
    "editable": false,
    "id": "BqNxaLsm29vS",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f39f6185a54850c2f1f9b5b2a17b7543",
     "grade": true,
     "grade_id": "feedback-tests",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "name": "21- Transfer Learning.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
