{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "deletable": false,
    "editable": false,
    "id": "24y1sw5Msdog",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c72cb50c0e638cb004dec850c91c6f1b",
     "grade": false,
     "grade_id": "cell-0ee2026dc35233b5",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "# Reinforcement Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "deletable": false,
    "editable": false,
    "id": "xLe2MhwUsdoi",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "27b264c04bfd4e8ba35f88d24eac77b2",
     "grade": false,
     "grade_id": "cell-6c42419557b8f132",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "from time import sleep\n",
    "from IPython.display import clear_output\n",
    "import random\n",
    "\n",
    "import gym\n",
    "import numpy as np\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "deletable": false,
    "editable": false,
    "id": "8V0QpDLVsdok",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "04fc115d6dcc23c5c058ef84dde2936b",
     "grade": false,
     "grade_id": "cell-36cbf46419269559",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "We will be using [OpenAI's gym](https://gym.openai.com/docs/) for rendering environments and we will specifically use the [Taxi-v2](https://gym.openai.com/envs/Taxi-v2/) environment for this exercise. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "colab_type": "code",
    "deletable": false,
    "editable": false,
    "id": "DsmkrWFZsdol",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "57661b0cbd0071ec3e8064152ac91d5c",
     "grade": false,
     "grade_id": "cell-ae8bb9fd4f2545d3",
     "locked": true,
     "schema_version": 3,
     "solution": false
    },
    "outputId": "4d98480f-a4e0-46b3-b10e-680fb35cea5d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current State: 26\n",
      "+---------+\n",
      "|R:\u001b[43m \u001b[0m| : :\u001b[34;1mG\u001b[0m|\n",
      "| : | : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|\u001b[35mY\u001b[0m| : |B: |\n",
      "+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load the Taxi-v2 environment\n",
    "env = gym.make(\"Taxi-v3\").env\n",
    "\n",
    "# Standardize expected results\n",
    "env.seed(0)\n",
    "env.reset()\n",
    "\n",
    "print(f\"Current State: {env.s}\")\n",
    "env.render()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "deletable": false,
    "editable": false,
    "id": "uWLARiDmsdon",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "dc2a866c67a68b7e0392bf4f9ab5d0c7",
     "grade": false,
     "grade_id": "cell-373c22c099142701",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "The above section just rendered an example view of the environment. For the Taxi-v2 environment,\n",
    "\n",
    "1. the block is the taxi and it is yellow if empty and green if it contains a passenger\n",
    "1. Pipe symbols `|` represent barriers preventing the taxi from moving in that direction\n",
    "1. R, G, Y, B are all the possible pickup or dropoff locations for a passenger\n",
    "1. Blue represents the current passenger's pickup location\n",
    "1. Purple represents the current passenger's dropoff location\n",
    "\n",
    "The reward scheme for this environment is as follows, \"your job is to pick up the passenger at one location and drop them off in another. You receive +20 points for a successful dropoff, and lose 1 point for every timestep it takes. There is also a 10 point penalty for illegal pick-up and drop-off actions.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "deletable": false,
    "editable": false,
    "id": "ffv6KTSqsdon",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f1d663986a59f94d6cb03dd3d23b8bae",
     "grade": false,
     "grade_id": "cell-73b4814ef8176fe2",
     "locked": true,
     "schema_version": 3,
     "solution": false
    },
    "outputId": "729b8429-85c0-441d-96b3-1243ebe98073"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The action space is discrete with 6 possibilities.\n",
      "The observation (state) space is discrete with 500 possibilities.\n"
     ]
    }
   ],
   "source": [
    "print(f\"The action space is discrete with {env.action_space.n} possibilities.\")\n",
    "print(f\"The observation (state) space is discrete with {env.observation_space.n} possibilities.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "deletable": false,
    "editable": false,
    "id": "1DNnjz0csdop",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "129dda2db9b3af51fe218cf4cd044163",
     "grade": false,
     "grade_id": "cell-eadba99486bd8679",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "The following actions are possible in the environment:\n",
    "\n",
    "1. Move south\n",
    "1. Move north\n",
    "1. Move east\n",
    "1. Move west\n",
    "1. Pick up passenger\n",
    "1. Drop off passenger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "deletable": false,
    "id": "dq1SLXaRsdop",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "194f3f42bf6fd716d67752983e962d56",
     "grade": false,
     "grade_id": "cell-5f22453e53fcf9cf",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def initialize_q_table(env):\n",
    "    \"\"\"Initialize a Q table for an environment with all 0s\n",
    "    \n",
    "    Args:\n",
    "        env (gym.envs): The environment\n",
    "    \n",
    "    Returns:\n",
    "        np.array: The Q table\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "\n",
    "    q=np.zeros((env.observation_space.n,env.action_space.n))\n",
    "    return q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "deletable": false,
    "editable": false,
    "id": "0yQVWF9Tsdor",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "89439d7ab26f71ec0aa9bd9b18cde47d",
     "grade": true,
     "grade_id": "cell-1f3967db32df3828",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert initialize_q_table(env).shape == (500, 6)\n",
    "xenv = gym.make(\"FrozenLake-v0\").env\n",
    "assert initialize_q_table(xenv).shape ==(16,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "deletable": false,
    "id": "Z1_glzqQsdot",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "bb5f4e29f42960f950f0acc632161d88",
     "grade": false,
     "grade_id": "cell-4b276160d41b4aa0",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def select_action(q_row, method, epsilon=0.5):\n",
    "    \"\"\"Select the appropriate action given a Q table row for the state and a chosen method\n",
    "    \n",
    "    Args:\n",
    "        q_row (np.array): The row from the Q table to utilize\n",
    "        method (str): The method to use, either \"random\" or \"epsilon\"\n",
    "        epsilon (float, optional): Defaults to 0.5. The epsilon value to use for epislon-greed action selection\n",
    "    \n",
    "    Raises:\n",
    "        NameError: If method specified is not supported\n",
    "    \n",
    "    Returns:\n",
    "        int: The index of the action to apply\n",
    "    \"\"\"\n",
    "    if method not in [\"random\", \"epsilon\"]:\n",
    "        raise NameError(\"Undefined method.\")\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    if( method==\"random\" and random.random() < epsilon):\n",
    "        return np.random.choice(q_row.size)\n",
    "    return q_row.argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "deletable": false,
    "editable": false,
    "id": "LVNJVk_gsdou",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ec78e64fb3d0b6d16e2eaf9019a600cb",
     "grade": true,
     "grade_id": "cell-436a8b9b98845dd8",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert select_action(np.array([1,2,3,4]), \"epsilon\", epsilon=0) == 3\n",
    "assert select_action(np.array([1,2,3,4]), \"epsilon\", epsilon=1) in range(4)\n",
    "assert select_action(np.array([1,2,3,4]), \"random\") in range(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "deletable": false,
    "editable": false,
    "id": "_mkan2lusdow",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "fa909ca128db7a5886bcb4b2e6225575",
     "grade": false,
     "grade_id": "cell-2171ed4400886241",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "The `env.step(action)` method takes a parameter that is the action the agent decides to apply and returns 4 values:\n",
    "1. The new state\n",
    "1. The received reward\n",
    "1. Whether you have completed the task\n",
    "1. Miscellaneous information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "deletable": false,
    "editable": false,
    "id": "fSpNbhsqsdow",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c8f3c85b8967d0c3131662c770503a19",
     "grade": false,
     "grade_id": "cell-219e07fb8178585a",
     "locked": true,
     "schema_version": 3,
     "solution": false
    },
    "outputId": "aedcf336-6c1f-4a67-9f92-9c589d06dfc2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An example returned from a step with action 0\n",
      "(475, -1, False, {'prob': 1.0})\n",
      "This returns the new state 475, the reward received (-1) based on performing the action 0, whether or not the task has been completed, False, and some additional miscellaneous info.\n"
     ]
    }
   ],
   "source": [
    "action = 0\n",
    "vals = env.step(action)\n",
    "print(f\"An example returned from a step with action 0\")\n",
    "print(vals)\n",
    "print(f\"This returns the new state {vals[0]}, the reward received ({vals[1]}) based on performing the action {action}, whether or not the task has been completed, {vals[2]}, and some additional miscellaneous info.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "deletable": false,
    "id": "gjAoVKUssdoy",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f930657e2f5fb7602cdb97d7ef001d78",
     "grade": false,
     "grade_id": "cell-0234e0a3e6f2eb0a",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def calculate_new_q_val(q_table, state, action, reward, next_state, alpha, gamma):\n",
    "    \"\"\"Calculate the updated Q table value for a particular state and action given the necessary parameters\n",
    "    \n",
    "    Args:\n",
    "        q_table (np.array): The Q table\n",
    "        state (int): The current state of the simulation's index in the Q table\n",
    "        action (int): The current action's index in the Q table\n",
    "        reward (float): The returned reward value from the environment\n",
    "        next_state (int): The next state of the simulation's index in the Q table (Based on the environment)\n",
    "        alpha (float): The learning rate\n",
    "        gamma (float): The discount rate\n",
    "    \n",
    "    Returns:\n",
    "        float: The updated action-value expectation for the state and action\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    max_Q=max(q_table[next_state])\n",
    "    Q_new=(1- alpha) * q_table[state, action] + alpha * (reward + gamma * max_Q)\n",
    "    \n",
    "    return Q_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "deletable": false,
    "editable": false,
    "id": "4mPvXDunsdoz",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ca2f0f747e9f62e7fda1f85770414aed",
     "grade": true,
     "grade_id": "cell-f5c631dceb6c6cf0",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "test_q = np.array([[1,2,3,4],[1,2,3,4],[1,2,3,4]])\n",
    "assert -0.05 < calculate_new_q_val(test_q, 0, 1, 10, 1, 0.1, 0.2) - 2.88 < 0.05\n",
    "assert -0.05 < calculate_new_q_val(test_q, 0, 1, 1, 1, 0.1, 0.1) - 1.94 < 0.05\n",
    "assert -0.05 < calculate_new_q_val(test_q, 0, 1, -11, 2, 0.1, 0.1) - 0.74 < 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "deletable": false,
    "editable": false,
    "id": "Df1_v9bisdo1",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "cd64b8626b3cfc824a0a4f42e37a9348",
     "grade": false,
     "grade_id": "cell-b7b2eccdd9ee9f58",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "epsilon1_params = {\n",
    "    \"method\": \"epsilon\",\n",
    "    \"epsilon\": 0.1,\n",
    "    \"alpha\": 0.1,\n",
    "    \"gamma\": 0.5\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "deletable": false,
    "editable": false,
    "id": "Hj_-Gf1csdo3",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "fb2ef67b6b51049b7ec5d7d478dcab11",
     "grade": false,
     "grade_id": "cell-15780bf5037e08f3",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "epsilon2_params = {\n",
    "    \"method\": \"epsilon\",\n",
    "    \"epsilon\": 0.3,\n",
    "    \"alpha\": 0.1,\n",
    "    \"gamma\": 0.5\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "deletable": false,
    "id": "JYLy4aIwsdo4",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ab25f1f541e256787bb12d1b5bac2819",
     "grade": false,
     "grade_id": "cell-13af0762ec7af495",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def train_sim(env, params, n=100):\n",
    "    \"\"\"Train a simulation on an environment and return its Q table\n",
    "    \n",
    "    Args:\n",
    "        env (gym.envs): The environment to train in\n",
    "        params (dict): The parameters needed to train the simulation: method (for action selection), epsilon, alpha, gamma\n",
    "        n (int, optional): Defaults to 100. The number of simulations to run for training\n",
    "    \n",
    "    Returns:\n",
    "        np.array: The trained Q table from the simulation\n",
    "    \"\"\"\n",
    "    my_q = initialize_q_table(env)\n",
    "    epsilon=params[\"epsilon\"]\n",
    "    alpha=params[\"alpha\"]\n",
    "    gamma=params[\"gamma\"]\n",
    "    method=params[\"method\"]\n",
    "    \n",
    "    for i in range(n):\n",
    "        current_state = env.reset()\n",
    "        done = False\n",
    "        \n",
    "        while not done:\n",
    "            # Get the next action based on current state\n",
    "            # Step through the environment with the selected action\n",
    "            # Update the qtable\n",
    "            \n",
    "            # YOUR CODE HERE\n",
    "            state=current_state\n",
    "            action=select_action(my_q[current_state], method, epsilon)\n",
    "            vals= env.step(action)\n",
    "            next_state=vals[0]\n",
    "            reward=vals[1]\n",
    "            q_value=calculate_new_q_val(my_q, state, action, reward, next_state, alpha, gamma)\n",
    "            my_q[current_state,action]=q_value\n",
    "            done=vals[2]\n",
    "            # Prep for next iteration\n",
    "            current_state = next_state \n",
    "\n",
    "        if (i+1) % 100 == 0:\n",
    "            print(f\"Simulation #{i+1:,} complete.\")\n",
    "        \n",
    "    return my_q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "deletable": false,
    "editable": false,
    "id": "8xAxJrZbsdo6",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b09d65393362da33ebb91b8cd2aa9677",
     "grade": false,
     "grade_id": "cell-9edcffba53e06847",
     "locked": true,
     "schema_version": 3,
     "solution": false
    },
    "outputId": "b3150415-07f2-4691-e3d3-3092e5e7aa07"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simulation #100 complete.\n",
      "Simulation #200 complete.\n",
      "Simulation #300 complete.\n",
      "Simulation #400 complete.\n",
      "Simulation #500 complete.\n",
      "Simulation #600 complete.\n",
      "Simulation #700 complete.\n",
      "Simulation #800 complete.\n",
      "Simulation #900 complete.\n",
      "Simulation #1,000 complete.\n",
      "Simulation #1,100 complete.\n",
      "Simulation #1,200 complete.\n",
      "Simulation #1,300 complete.\n",
      "Simulation #1,400 complete.\n",
      "Simulation #1,500 complete.\n",
      "Simulation #1,600 complete.\n",
      "Simulation #1,700 complete.\n",
      "Simulation #1,800 complete.\n",
      "Simulation #1,900 complete.\n",
      "Simulation #2,000 complete.\n",
      "Simulation #2,100 complete.\n",
      "Simulation #2,200 complete.\n",
      "Simulation #2,300 complete.\n",
      "Simulation #2,400 complete.\n",
      "Simulation #2,500 complete.\n",
      "Simulation #2,600 complete.\n",
      "Simulation #2,700 complete.\n",
      "Simulation #2,800 complete.\n",
      "Simulation #2,900 complete.\n",
      "Simulation #3,000 complete.\n",
      "Simulation #3,100 complete.\n",
      "Simulation #3,200 complete.\n",
      "Simulation #3,300 complete.\n",
      "Simulation #3,400 complete.\n",
      "Simulation #3,500 complete.\n",
      "Simulation #3,600 complete.\n",
      "Simulation #3,700 complete.\n",
      "Simulation #3,800 complete.\n",
      "Simulation #3,900 complete.\n",
      "Simulation #4,000 complete.\n",
      "Simulation #4,100 complete.\n",
      "Simulation #4,200 complete.\n",
      "Simulation #4,300 complete.\n",
      "Simulation #4,400 complete.\n",
      "Simulation #4,500 complete.\n",
      "Simulation #4,600 complete.\n",
      "Simulation #4,700 complete.\n",
      "Simulation #4,800 complete.\n",
      "Simulation #4,900 complete.\n",
      "Simulation #5,000 complete.\n",
      "Simulation #5,100 complete.\n",
      "Simulation #5,200 complete.\n",
      "Simulation #5,300 complete.\n",
      "Simulation #5,400 complete.\n",
      "Simulation #5,500 complete.\n",
      "Simulation #5,600 complete.\n",
      "Simulation #5,700 complete.\n",
      "Simulation #5,800 complete.\n",
      "Simulation #5,900 complete.\n",
      "Simulation #6,000 complete.\n",
      "Simulation #6,100 complete.\n",
      "Simulation #6,200 complete.\n",
      "Simulation #6,300 complete.\n",
      "Simulation #6,400 complete.\n",
      "Simulation #6,500 complete.\n",
      "Simulation #6,600 complete.\n",
      "Simulation #6,700 complete.\n",
      "Simulation #6,800 complete.\n",
      "Simulation #6,900 complete.\n",
      "Simulation #7,000 complete.\n",
      "Simulation #7,100 complete.\n",
      "Simulation #7,200 complete.\n",
      "Simulation #7,300 complete.\n",
      "Simulation #7,400 complete.\n",
      "Simulation #7,500 complete.\n",
      "Simulation #7,600 complete.\n",
      "Simulation #7,700 complete.\n",
      "Simulation #7,800 complete.\n",
      "Simulation #7,900 complete.\n",
      "Simulation #8,000 complete.\n",
      "Simulation #8,100 complete.\n",
      "Simulation #8,200 complete.\n",
      "Simulation #8,300 complete.\n",
      "Simulation #8,400 complete.\n",
      "Simulation #8,500 complete.\n",
      "Simulation #8,600 complete.\n",
      "Simulation #8,700 complete.\n",
      "Simulation #8,800 complete.\n",
      "Simulation #8,900 complete.\n",
      "Simulation #9,000 complete.\n",
      "Simulation #9,100 complete.\n",
      "Simulation #9,200 complete.\n",
      "Simulation #9,300 complete.\n",
      "Simulation #9,400 complete.\n",
      "Simulation #9,500 complete.\n",
      "Simulation #9,600 complete.\n",
      "Simulation #9,700 complete.\n",
      "Simulation #9,800 complete.\n",
      "Simulation #9,900 complete.\n",
      "Simulation #10,000 complete.\n",
      "Simulation #100 complete.\n",
      "Simulation #200 complete.\n",
      "Simulation #300 complete.\n",
      "Simulation #400 complete.\n",
      "Simulation #500 complete.\n",
      "Simulation #600 complete.\n",
      "Simulation #700 complete.\n",
      "Simulation #800 complete.\n",
      "Simulation #900 complete.\n",
      "Simulation #1,000 complete.\n",
      "Simulation #1,100 complete.\n",
      "Simulation #1,200 complete.\n",
      "Simulation #1,300 complete.\n",
      "Simulation #1,400 complete.\n",
      "Simulation #1,500 complete.\n",
      "Simulation #1,600 complete.\n",
      "Simulation #1,700 complete.\n",
      "Simulation #1,800 complete.\n",
      "Simulation #1,900 complete.\n",
      "Simulation #2,000 complete.\n",
      "Simulation #2,100 complete.\n",
      "Simulation #2,200 complete.\n",
      "Simulation #2,300 complete.\n",
      "Simulation #2,400 complete.\n",
      "Simulation #2,500 complete.\n",
      "Simulation #2,600 complete.\n",
      "Simulation #2,700 complete.\n",
      "Simulation #2,800 complete.\n",
      "Simulation #2,900 complete.\n",
      "Simulation #3,000 complete.\n",
      "Simulation #3,100 complete.\n",
      "Simulation #3,200 complete.\n",
      "Simulation #3,300 complete.\n",
      "Simulation #3,400 complete.\n",
      "Simulation #3,500 complete.\n",
      "Simulation #3,600 complete.\n",
      "Simulation #3,700 complete.\n",
      "Simulation #3,800 complete.\n",
      "Simulation #3,900 complete.\n",
      "Simulation #4,000 complete.\n",
      "Simulation #4,100 complete.\n",
      "Simulation #4,200 complete.\n",
      "Simulation #4,300 complete.\n",
      "Simulation #4,400 complete.\n",
      "Simulation #4,500 complete.\n",
      "Simulation #4,600 complete.\n",
      "Simulation #4,700 complete.\n",
      "Simulation #4,800 complete.\n",
      "Simulation #4,900 complete.\n",
      "Simulation #5,000 complete.\n",
      "Simulation #5,100 complete.\n",
      "Simulation #5,200 complete.\n",
      "Simulation #5,300 complete.\n",
      "Simulation #5,400 complete.\n",
      "Simulation #5,500 complete.\n",
      "Simulation #5,600 complete.\n",
      "Simulation #5,700 complete.\n",
      "Simulation #5,800 complete.\n",
      "Simulation #5,900 complete.\n",
      "Simulation #6,000 complete.\n",
      "Simulation #6,100 complete.\n",
      "Simulation #6,200 complete.\n",
      "Simulation #6,300 complete.\n",
      "Simulation #6,400 complete.\n",
      "Simulation #6,500 complete.\n",
      "Simulation #6,600 complete.\n",
      "Simulation #6,700 complete.\n",
      "Simulation #6,800 complete.\n",
      "Simulation #6,900 complete.\n",
      "Simulation #7,000 complete.\n",
      "Simulation #7,100 complete.\n",
      "Simulation #7,200 complete.\n",
      "Simulation #7,300 complete.\n",
      "Simulation #7,400 complete.\n",
      "Simulation #7,500 complete.\n",
      "Simulation #7,600 complete.\n",
      "Simulation #7,700 complete.\n",
      "Simulation #7,800 complete.\n",
      "Simulation #7,900 complete.\n",
      "Simulation #8,000 complete.\n",
      "Simulation #8,100 complete.\n",
      "Simulation #8,200 complete.\n",
      "Simulation #8,300 complete.\n",
      "Simulation #8,400 complete.\n",
      "Simulation #8,500 complete.\n",
      "Simulation #8,600 complete.\n",
      "Simulation #8,700 complete.\n",
      "Simulation #8,800 complete.\n",
      "Simulation #8,900 complete.\n",
      "Simulation #9,000 complete.\n",
      "Simulation #9,100 complete.\n",
      "Simulation #9,200 complete.\n",
      "Simulation #9,300 complete.\n",
      "Simulation #9,400 complete.\n",
      "Simulation #9,500 complete.\n",
      "Simulation #9,600 complete.\n",
      "Simulation #9,700 complete.\n",
      "Simulation #9,800 complete.\n",
      "Simulation #9,900 complete.\n",
      "Simulation #10,000 complete.\n",
      "CPU times: user 8.35 s, sys: 255 ms, total: 8.61 s\n",
      "Wall time: 8.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "n = 10000\n",
    "epsilon1_q = train_sim(env, epsilon1_params, n)\n",
    "epsilon2_q = train_sim(env, epsilon2_params, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "deletable": false,
    "id": "SvymP6AEsdo7",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "89d09960d90b298c08ccedbd1983bf09",
     "grade": false,
     "grade_id": "cell-2100a877594cd931",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def test_sim(env, q_table, n=100, render=False):\n",
    "    \"\"\"Test an environment using a pre-trained Q table\n",
    "    \n",
    "    Args:\n",
    "        env (gym.envs): The environment to test\n",
    "        q_table (np.array): The pretrained Q table\n",
    "        n (int, optional): Defaults to 100. The number of test iterations to run\n",
    "        render (bool, optional): Defaults to False. Whether to display a rendering of the environment\n",
    "    \n",
    "    Returns:\n",
    "        np.array: Array of length n with each value being the cumulative reward achieved in the simulation\n",
    "    \"\"\"\n",
    "    rewards = []\n",
    "    \n",
    "    for i in range(n):\n",
    "        current_state = env.reset()\n",
    "\n",
    "        tot_reward = 0\n",
    "        done = False\n",
    "        step = 0\n",
    "\n",
    "        while not done:\n",
    "            \n",
    "            # Determine the best action\n",
    "            # Step through the environment\n",
    "            \n",
    "            # YOUR CODE HERE\n",
    "            random_action = select_action(q_table[current_state],\"random\")\n",
    "            epsilon_action = select_action(q_table[current_state], \"epsilon\")\n",
    "            random_vals = env.step(random_action)\n",
    "            epsilon_vals = env.step(epsilon_action)\n",
    "\n",
    "\n",
    "            reward_random = random_vals[1]\n",
    "            reward_epsilon = epsilon_vals[1]\n",
    "\n",
    "            if(reward_epsilon > reward_random):\n",
    "                current_state=epsilon_vals[0]\n",
    "                reward=reward_epsilon\n",
    "                done=epsilon_vals[2]\n",
    "            else:\n",
    "                current_state=random_vals[0]\n",
    "                reward=reward_random\n",
    "                done=random_vals[2]\n",
    "\n",
    "            tot_reward += reward\n",
    "            step +=1\n",
    "            if render:\n",
    "                clear_output(wait=True)\n",
    "                print(f\"Simulation: {i + 1}\")\n",
    "                env.render()\n",
    "                print(f\"Step: {step}\")\n",
    "                print(f\"Current State: {current_state}\")\n",
    "                print(f\"Action: {action}\")\n",
    "                print(f\"Reward: {reward}\")\n",
    "                print(f\"Total rewards: {tot_reward}\")\n",
    "                sleep(.2)\n",
    "            if step == 50:\n",
    "                print(\"Agent got stuck. Quitting...\")\n",
    "                sleep(.5)\n",
    "                break\n",
    "        \n",
    "        rewards.append(tot_reward)\n",
    "    \n",
    "    return np.array(rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "deletable": false,
    "editable": false,
    "id": "1As73yPPsdo9",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f23d9ff8e15594d3a1ab28725984fccd",
     "grade": false,
     "grade_id": "cell-18ab739306cf86ff",
     "locked": true,
     "schema_version": 3,
     "solution": false
    },
    "outputId": "9dfa0c21-2b4c-4517-91b7-14395c7cce33"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent got stuck. Quitting...\n"
     ]
    }
   ],
   "source": [
    "# Add render=True to see the simulation running\n",
    "epsilon1_rewards = test_sim(env, epsilon1_q, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "deletable": false,
    "editable": false,
    "id": "pFDZmSPvsdo-",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3d50a42b8e7439f5847b220dcf6d8fcc",
     "grade": false,
     "grade_id": "cell-b4310173795ca573",
     "locked": true,
     "schema_version": 3,
     "solution": false
    },
    "outputId": "b7c10cbf-4f25-4842-b963-c763fce2c756"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent got stuck. Quitting...\n",
      "Agent got stuck. Quitting...\n"
     ]
    }
   ],
   "source": [
    "epsilon2_rewards = test_sim(env, epsilon2_q, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "deletable": false,
    "editable": false,
    "id": "o54oFYm-sdpA",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "602cd8f63c3ca11004c922bf9c01e79c",
     "grade": false,
     "grade_id": "cell-0a858504adc25ae1",
     "locked": true,
     "schema_version": 3,
     "solution": false
    },
    "outputId": "1ea38418-22b3-4288-9296-98342b6fe844"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The first epsilon greedy training method was able to get a median reward of 7.0.\n",
      "The second epsilon greedy training method was able to get a median reward of 7.0.\n"
     ]
    }
   ],
   "source": [
    "print(f\"The first epsilon greedy training method was able to get a median reward of {np.median(epsilon1_rewards)}.\")\n",
    "print(f\"The second epsilon greedy training method was able to get a median reward of {np.median(epsilon2_rewards)}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "deletable": false,
    "editable": false,
    "id": "puxhW3w2sdpB",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "991f059b31e42268b4c8fbc5df93fb80",
     "grade": true,
     "grade_id": "cell-a4db87228ab068a8",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert np.median(epsilon1_rewards) > 5\n",
    "assert np.median(epsilon2_rewards) > 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "deletable": false,
    "editable": false,
    "id": "kIcOntxgsdpE",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d0396d41ebf05afc94934500ec6d00c6",
     "grade": false,
     "grade_id": "cell-b19c1d376892e2c1",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "## Feedback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "deletable": false,
    "id": "f39jjf-IsdpF",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ed936ab53a1391c5e6af8df699a1dbf5",
     "grade": false,
     "grade_id": "feedback",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def feedback():\n",
    "    \"\"\"Provide feedback on the contents of this exercise\n",
    "    \n",
    "    Returns:\n",
    "        string\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    return \"This was a ton of coding with very little documentation.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "deletable": false,
    "editable": false,
    "id": "VauH3JQKsdpI",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f39f6185a54850c2f1f9b5b2a17b7543",
     "grade": true,
     "grade_id": "feedback-tests",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "22 - Reinforcement Learning.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
